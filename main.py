# This is a sample Python script.
# Press Shift+F10 to execute it or replace it with your code.
# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.
# Load libraries
import pandas as pd
from six import StringIO
#Scikit-learn:Python library for machine learning
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
from IPython.display import Image
import pydotplus
from sklearn.model_selection import train_test_split
import random
from sklearn.utils import shuffle

def my_model1():

    print('This Is Model 1')
    print('----------------------------------------------------------------------------')

    col_names = ['NPG', 'PGL', 'DIA', 'TSF', 'INS', 'BMI', 'DPF', 'AGE', 'Diabetic']
    # load dataset
    #By default, pandas assumes that the first row contains column names
    pima = pd.read_csv("diabetes.csv", header=None,skiprows=1, names=col_names)

    pima.head(769)

    #split dataset in features and target variable
    feature_cols = ['NPG', 'PGL', 'DIA', 'INS', 'BMI', 'DPF', 'AGE']
    #pima is original DataFrame containing the data
    X = pima[feature_cols] # Features, "X" that contains only the columns specified in the feature_cols
    y = pima.Diabetic # Target variable

    # Read the CSV file into a DataFrame
    df = pd.read_csv('diabetes.csv')

    # Shuffle the DataFrame 'shuffle' function from the scikit-learn library
    shuffled_df = shuffle(df)

    # Write the shuffled DataFrame back to a CSV file using the 'to_csv' function from pandas.
    shuffled_df.to_csv('diabetes.csv', index=False)


    # Split dataset into training set and test set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) # 70% training and 30% test

    # clf = DecisionTreeClassifier(criterion="entropy", max_depth=3)

    # Create Decision Tree classifer object using the DecisionTreeClassifier() function
    clf = DecisionTreeClassifier()

    # Train Decision Tree Classifer (train the decision tree classifier by calling the fit())
    # This trains the decision tree model using the provided training data
    clf = clf.fit(X_train, y_train)

    # Predict the response for test dataset
    # It returns the predicted target variable values based on the trained model
    y_pred = clf.predict(X_test)

    # Model Accuracy, how often is the classifier correct?
    # function is used to calculate the accuracy of a classification model
    print("Accuracy:", metrics.accuracy_score(y_test, y_pred))

    print('----------------------------------------------------------------------------')
    #StringIO object is created to store the dot data generated by export_graphviz
    dot_data = StringIO()
    export_graphviz(clf, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
    # write_png method is used to save the graph as a png
    graph.write_png('diabetes.png')
    # creates a png image of the decision tree graph, which is displayed using the Image function
    Image(graph.create_png())

    #/////////////////////////////////////////////////////////////////////////////////////////////////

    # Calculate the distribution of the target class
    class_distribution = pima['Diabetic'].value_counts(normalize=True)*100

    # Print the distribution
    print("Target Class Distribution:")
    print(class_distribution)


    print('----------------------------------------------------------------------------')
    #///////////////////////////////////////////////////////////

    # Calculate statistics
    statistics = pima.describe().transpose()

    # Print statistics table
    print("Attribute\tMean\t\tMedian\t\tStd\t\t\tMin\t\t\tMax\t\t\tCount")
    for attr, row in statistics.iterrows():
        mean = row['mean']
        median = row['50%']
        std = row['std']
        min_val = row['min']
        max_val = row['max']
        count = row['count']
        print(f"{attr}\t\t\t{mean:.2f}\t\t{median:.2f}\t\t{std:.2f}\t\t{min_val:.2f}\t\t{max_val:.2f}\t\t{count:.0f}")

    print(',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,')
    import matplotlib
    matplotlib.use('TkAgg')
    import matplotlib.pyplot as plt

    # Create scatter plot
    for col in feature_cols:
        plt.scatter(X[col], y, label=col)

    plt.xlabel('Features')
    plt.ylabel('Diabetic')
    plt.legend()
    plt.title('Model_1: Plot of Features vs Diabetic')
    plt.show()


my_model1()

def my_model2():
    import pandas as pd2


    print('############################################################################')
    print('This Is Model 2')
    print('----------------------------------------------------------------------------')

    col_names = ['NPG', 'PGL', 'DIA', 'TSF', 'INS', 'BMI', 'DPF', 'AGE', 'Diabetic']
    # load dataset
    pima = pd2.read_csv("diabetes.csv", header=None, skiprows=1, names=col_names)
    pima.head(769)

    # split dataset in features and target variable
    feature_cols = ['NPG', 'PGL', 'DIA', 'INS', 'BMI', 'DPF', 'AGE']
    X = pima[feature_cols]  # Features
    y = pima.Diabetic  # Target variable

    # Read the CSV file into a DataFrame
    df = pd2.read_csv('diabetes.csv')

    # Shuffle the DataFrame
    shuffled_df = shuffle(df)

    # Write the shuffled DataFrame back to a CSV file
    shuffled_df.to_csv('diabetes.csv', index=False)

    # Split dataset into training set and test set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,random_state=0)  # 50% training and 50% test

    # Create Decision Tree classifer object
    clf = DecisionTreeClassifier()

    # Train Decision Tree Classifer
    clf = clf.fit(X_train, y_train)

    # Predict the response for test dataset
    y_pred = clf.predict(X_test)

    # Model Accuracy, how often is the classifier correct?
    print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
    print('----------------------------------------------------------------------------')

    dot_data = StringIO()
    export_graphviz(clf, out_file=dot_data,
                    filled=True, rounded=True,
                    special_characters=True, feature_names=feature_cols, class_names=['0', '1'])
    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
    graph.write_png('diabetes2.png')
    Image(graph.create_png())

    # /////////////////////////////////////////////////////////////////////////////////////////////////

    # Calculate the distribution of the target class
    class_distribution = pima['Diabetic'].value_counts(normalize=True) * 100

    # Print the distribution
    print("Target Class Distribution:")
    print(class_distribution)
    print('----------------------------------------------------------------------------')
    # ///////////////////////////////////////////////////////////

    # Calculate statistics
    statistics = pima.describe().transpose()

    # Print statistics table
    print("Attribute\tMean\t\tMedian\t\tStd\t\t\tMin\t\t\tMax\t\t\tCount")
    for attr, row in statistics.iterrows():
        mean = row['mean']
        median = row['50%']
        std = row['std']
        min_val = row['min']
        max_val = row['max']
        count = row['count']
        print(f"{attr}\t\t\t{mean:.2f}\t\t{median:.2f}\t\t{std:.2f}\t\t{min_val:.2f}\t\t{max_val:.2f}\t\t{count:.0f}")
    print('----------------------------------------------------------------------------')

    import matplotlib
    matplotlib.use('TkAgg')
    import matplotlib.pyplot as plt2

    # Create scatter plot
    for col in feature_cols:
        plt2.scatter(X[col], y, label=col)

    plt2.xlabel('Features')
    plt2.ylabel('Diabetic')
    plt2.legend()
    plt2.title('Model_2: Plot of Features vs Diabetic')
    plt2.show()

my_model2()










